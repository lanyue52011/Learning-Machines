<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><title>LM101-019 (Rerun): How to Enhance Intelligence with a Robotic Body (Embodied Cognition) - Learning Machines 101
</title></head><body><div>Episode Summary:<br/>Embodied cognition emphasizes the design of complex artificially intelligent systems may be both vastly simplified and vastly enhanced if we view the robotic bodies of artificially intelligent systems as important contributors to intelligent behavior.<br/>Show Notes:<br/>Hello everyone! Welcome to the ninth podcast in the podcast series Learning Machines 101. In this series of podcasts my goal is to discuss important concepts of artificial intelligence and machine learning in hopefully an entertaining and educational manner. In this podcast episode, we introduce the concept of “embodied cognition”. Embodied cognition emphasizes the design of complex artificially intelligent systems may be both vastly simplified and vastly enhanced if we view the robotic bodies of artificially intelligent systems as important contributors to intelligent behavior in specific environments.<br/>What is “intelligence”? Many would consider Albert Einstein to be an extremely intelligent person because of his important contributions to the field of theoretical physics. However, if Albert Einstein was stranded in a primitive jungle without any equipment he might have difficulty surviving in such an environment even though a primitive animal might easily survive in such an environment. Does this mean that the primitive animal is “smarter” than Albert Einstein in the jungle? Suppose there was a plumbing problem in the house and Albert Einstein couldn’t figure out how to fix the plumbing problem but a smart plumber figures out how to fix the plumbing problem. Is the plumber smarter than Albert Einstein?<br/>In our day to day lives, we encounter similar situations. We may be experts in one area, yet novices in another. One individual may be a highly intelligent nuclear physicist and a novice at financial matters, while another individual may be a highly intelligent financial genius yet a novice in nuclear physics. Thus, intelligence does not appear to be an absolute quantity but rather domain specific. We can have a “smart” pencil sharpener which figures out how to best sharpen your pencils and we can have a “smart” dog who helps us in search and rescue operations. We can also have a “smart phone” which helps us communicate with others and manage our daily schedules.  However, the “smart phone” will not be very helpful to us in sharpening pencils and the pencil sharpener will not be helpful for sending an email to a friend.  These devices only “show off” their intelligent behavior in the specific environments in which they were designed to function.<br/>Based upon these considerations, we define intelligence as follows.<br/>“Intelligent behavior is defined as a collection of behaviors for an organism that lead to successful outcomes for the organism within a particular environment.”<br/>This definition thus specifies the concept of intelligent behavior not in an absolute sense but rather with respect to a specific definition of “success” and a specific definition of the organism’s “environment”. According to this definition of intelligence, we can not determine if an organism is intelligent unless we have defined the concepts of “success” and “environment”.<br/>These observations lead to a crucial point. Intelligence is not an absolute quantity but ultimately arises from complex interactions between the organism and its environment. For this reason, the design of intelligent systems requires that one carefully considers the environment of the artificially intelligent machine and how the artificially intelligent machine interacts with its environment.<br/>If the organism is physically designed to efficiently interact with its environment in a particular way, then those interactions are determined not only by the laws of the mind but by the laws of physics. The “intelligent behavior” of the organism arises, in part, from the physical structure of the organism and how the organism’s physical structure interacts with the organism’s physical environment.<br/>Suppose that we want to build a machine that can recognize a chair in its environment. Consider the problem of identifying the features of a chair. Chairs can be constructed from combinations of wood, plastic, metal, and fabric. Chairs can be small and they can be large. Chairs can be constructed from curved or straight components. Chairs can be constructed from a wide variety of colors. Suppose we identify a wide variety of chairs including desk chairs, office chairs, bar stools, recliner chairs, bean bag chairs, park benches, and dining room chairs. Next,  we construct a list that includes the features of all of these different types of chairs. As a result,  we would have a very long list of features that are characteristic of chairs. Such a long list of features would greatly complicate problems of inference and learning because many of these features would be irrelevant. The inference and learning machine’s job could be complicated if the machines uses many irrelevant features to represent objects and entities in the world. Which features should such a machine use? Presumably it should use features which help the machine make discriminations which support its success within its environment. We don’t want to represent objects in the world as large arbitrary collections of features. Ideally, we would like to use a relatively small select group of features that help the artificially intelligent machine make the necessary discriminations for it to be successful in its environmental niche.<br/>So, to return to the problem of identifying the features of chairs, we need to ask ourselves what properties of a chair are going to be important to an artificially intelligent machine. One important characteristic of chairs is that people can sit on chairs. Thus, one can examine typical lengths of human legs and the dynamics of typical human legs and use these observable physical properties to identify a set of physical constraints that allows a human being to sit on that object. One might then use that set of physical constraints to check if an object is “sittable”. An object which is not sittable would not be considered to be a chair. Features of this type which can be defined in terms of physical constraints of how an organism’s physical body can interact with a particular object in a particular environment for the purpose of specifying potential functional relationships are sometimes called “affordances”.<br/>Representing knowledge in terms of affordances would help an intelligent system to understand how a tree stump or a large rock in the middle of a forest could be used as a chair.  If the physical attributes of a tree stump is such that a human could sit on it, then the tree stump is potentially a chair for a human even though it may not be a chair for an elephant.  The use of affordance type features offers a possible solution to a classic problem in artificial intelligence called the “symbol grounding problem”. The symbol grounding problem is concerned with the creation of semantic features which are not arbitrary but, in fact, are determined by semantic constraints imposed by the real physical world.<br/>But we can take these ideas one step further. Consider a world-class human athlete who might be competing in a basketball game or demonstrating a complex gymnastic routine. Or alternatively, a world-class pianist providing a public performance. The skilled athlete or musician is not consciously thinking of exactly how they will point their toes or move their finger tips at each instant in time rather they are more focused upon executing highly complex behavioral patterns rather than individual motor actions. Their physical body is actively participating in the performance. For example, an unskilled typist will hit one key on the keyboard at a time and consciously reflect upon which key to select next. This process is extremely inefficient and wasteful of cognitive resources. On the other hand, a skilled typist looks ahead. As the skilled typist’s hands approach the keyboard, all of the fingers in the hand are already positioned to type the next sequence of letters. And, once the first finger hits the keyboard, the touch of that first finger to the keyboard key initiates a retraction of that finger while simultaneously signaling the next finger which is waiting its turn to perform its action. Not only is the skilled athlete or musician executing highly complex behavioral patterns rather than individual motor actions, these patterns are guided in part by direct feedback from the environment rather than solely from an error signals generated by comparing the generated motor behavior with a brain-generated detailed mental model of the desired motor behavior.<br/>Another way to think about this is to consider the following thought experiment where we have an artificially intelligent robot such as DATA from Star Trek: The Next Generation. Assume that DATA does not know how to play racquetball. Now suppose we take a human racquetball player and surgically switch the human head of the racquetball player with the robot head of DATA. So now we have a human racquetball player with a robot head and a human racquetball head on a robot body. Where does the “knowledge” required to play the game of racquetball reside? One might argue that it resides partially in both entities but one could also argue that it completely resides in neither entity.<br/>Now consider an autonomous robot vehicle designed to collect scientific data on the moon. The vehicle travels along the surface of the moon collecting data. Suddenly, the vehicle stops because a large rock is in the path of the vehicle. Suppose our goal is to make this autonomous vehicle artificially intelligent so that it can continue collecting data even if its encounters a rock in its path. One idea is that we could design the vehicle with sensor arrays so that it can assess the relative size of the rock and estimate the rock’s diameter. Once the rock’s diameter has been estimated, the vehicle could recalculate a new course designed to avoid the rock. These calculations would need to take into account issues such as accurate interpretation of the sensor data so that the rock’s diameter could be accurately assessed. This might require that the robot vehicle contains realistic three-dimensional models of rock obstacles and algorithms for using sensor data to construct these internal three-dimensional rock representations. These calculations would also need to include methods for comparing the autonomous robot vehicle’s plan for navigating the moon’s surface with the location of the rock blocking its path and a new plan would have to be constructed. This would require planning algorithms. Then the robot would try to follow this new plan and could monitor its progress by comparing the error signal between the new plan it had developed and observations of its external environment. This latter aspect would require still an additional collection of algorithms for monitoring and updating the behavior of the robot vehicle.<br/>Thus, this method would require accurate sensor measurement instrumentation, logical or probabilistic rules for interpreting the sensor data, logical or probabilistic rules for designing a new course on the lunar surface, and then additional logical or probabilistic rules for monitoring the robot vehicle’s performance as it implemented the new plan.<br/>The method we have just discussed is very general and very powerful when properly implemented. However, such methodology is not only challenging to implement but also might be challenging to implement in a robust manner so that it will work in a large variety of environments. It is also very expensive and complicated to implement.<br/>There is, however, a much simpler solution!<br/>What is the simpler solution?<br/>We simply give the autonomous robot land vehicle gigantic wheels so that it can just roll over large rocks! Then it doesn’t have to figure out how to go around them!<br/>But what about really big obstacles?<br/>In such cases, if it encountered an obstacle which it could not roll over, one might simply provide the vehicle with the heuristic rule to “back up” a few feet, implement a course direction change of 10 degrees from the original heading and then continue in a forward direction.  Using this heuristic, the robot land vehicle might initially stop, then back up, alter its direction and then move forward. In some cases, this process might have to be repeated several times before the vehicle could go around the obstacle. Notice that the vehicle solves the problem of going around the obstacle in this latter case through a sequence of iterative interactions with its environment. That is, through a trial and error approach rather than attempting to construct a detailed mental model of the world and then designing a solution for navigation consistent with that mental model.<br/>The use of heuristics such as larger wheels or a “back up and change course direction” strategiy, results in a design that is not only easier and less expensive to implement but also may provide a more robust solution than a design dependent upon large knowledge bases and complicated inference.<br/>By incorporating these two heuristic rules into the autonomous robot land vehicle, it is not necessary to provide the robot land vehicle with a large complex set of rules and procedures for computing with those rules. In some sense, the robot’s body and robot’s environment contribute to the intelligent behavior of the robot land vehicle. If the robot land vehicle’s environment changes in a fundamental way, the robot’s behavior becomes less intelligent.<br/>Massachusetts Institute of Technology Professor Emeritus Rodney Brooks has been a long-term leader in incorporating methods of embodied cognition into the development of intelligent robotic systems. Using the principles of embodied cognition, he has developed many robotic systems over the past few decades. In the late 1980’s, he and his doctoral student Jonathan Connell created the robot Herbert which was designed to wander the halls of MIT looking for empty soda cans. Once he identified a soda can, he would pick up the soda can and bring it back to his home.<br/>It is important to emphasize that Herbert was not programmed with knowledge of the layout of rooms, offices, and hallways of MIT. Herbert did not have knowledge of the concept of the shape and size of soda cans. Herbert was not programmed with the ability to design and implement complex plans of actions. Herbert did not have rules for trying to interpret the identity of objects in a visual scene. Herbert did not have rules for determining whether it was looking at a far away small object or very close large object.  Herbert did not have rules for moving its body and hands in a particular way to grab a soda can. Herbert did not have rules for controlling its behavior in a detailed way for fine-grained actions such as reaching for a soda can or large-scale actions such as traveling across a room. And Herbert was not a goal-driven robot which developed plans to achieve its goals. So how did Herbert work?<br/>Herbert was simply provided with the ability to execute a small number of behaviors. These behaviors were not represented as logical or even probabilistic rules but rather were represented in terms of Herbert’s physical robot body. Herbert used infrared sensors to identify the presence of walls and obstacles as it was moving and it tried to move in a direction such that it was traveling along side of a wall. Herbert also used a laser beam and a special detector to detect the location of soda can like objects in three-dimensional space.<br/>Once the soda can object was detected in the visual field, Herbert moved its body closer to the soda can object. If the soda can object still had the properties of a soda can object when Herbert was next to the object, Herbert would extend its robot hand into position to execute a grabbing motion. When infrared beams generated from the robot hand and detected by special sensors on that same robot hand were disrupted in a particular manner, this indicated to the robot that an object was graspable. The robot hand also has mechanical sensors that would detect the presence of physical contact with an object to also help identify situations where an object was ready for grasping. When the robot hand has been oriented to grasp an object, the robot hand would then grasp the object. The weight of the soda can object was assessed, if the soda can object weight was not similar to that of an empty soda can then the robot hand would not take the soda can object. If the weight was similar to that of an empty soda can, then the robot hand would automatically retract while continuing to hold the empty soda can object. Finally, because Herbert simply recorded his trip route from his home to it’s current location by recording the number of turns and the distance between turns, Herbert could then use this stored trip route information to bring the empty soda can object back to its lair.<br/>The robot Herbert exemplifies many important principles of embodied cognition. The robot Herbert does not have to build a detailed internal model of the external world, construct plans for navigating and exploring the external world using that internal model, or use that internal model to monitor and guide its implementation of its plans. Rather the robot Herbert comes equipped with behavioral building blocks such as: soda can grabbing, wall following, arm retraction, detection of soda can like objects, rejection of objects that are not similar to empty soda cans, and route retracing. Many components of these behavioral building blocks are not represented as abstract logical or even probabilistic rules but rather correspond to robotic body parts. Herbert only follows a relatively small number of heuristic rules in order to guide its behavior. Since the number of rules are small and these rules are relatively simple, Herbert’s behavior is relatively fast, robust, and reliable for a variety of different environments. Also there is not a central guidance mechanism for deciding which behavioral building block should be activated but rather each behavioral building block operates in a relatively autonomous and opportunistic manner with very minimal constraints for resolving rule conflicts.<br/>If you go to the website: www.learningmachines101.com you will find a link to a video<br/>Of Herbert the Soda Can Collecting Robot in action. The video is about 3 minutes long!!<br/>Click here to see a video of Herbert the Soda Can Collecting Robot!<br/>It should be noted that Herbert was created in the late 1980’s. Since then, Professor Brooks has created several robot companies. In the 1990’s, Professor Brooks created the company iROBOT (click here to visit the iROBOT website) which produces little robots that scurry around your house sweeping and vacuuming your floors without any human intervention. When the robot has completed its tasks, it returns to its charging station!! More recently, Professor Brooks has created a new company called Rethink Robotics (click here to visit the Rethink Robotics website) which is producing an advanced industrial robot. This new advanced industrial robot includes special patented technology which uses “series elastic actuators” which are spring-based and have human like response properties. Standard robot actuators involve a motor which turns gears. The flow of information is essentially one directional so that the actuator is unable to assess the force that it is exerting on an object. The new spring-based actuator is more effective at providing greater precision control of the robot arm while reducing the changes of the robot arm generating forces of inappropriate magnitudes.<br/>The embodied cognition perspective provides a number of important insights regarding the development and design of artificially intelligent systems. First, even a non-robotic disembodied rule-based system such as discussed in Episode 3 uses features. Embodied cognition provides guidance for choosing physically measurable and functionally meaningful features which are sometimes called “affordances”. Objects which have physical characteristics enabling humans to sit on them are chairs. Areas of space with physical characteristics which allow humans to move from one room to another are doorways. Second, a relatively simple specialized physical mechanism may sometimes provide a substantially more robust yet simpler implementation of a disembodied complex rule-based system. For example, the disembodied cognition approach might advocate designing a rule-based system to send sequential instructions to open and close the fingers of a robotic hand for the purpose of grasping a soda can. The embodied cognition approach might use a robotic hand that automatically closes a soda can of the appropriate weight when that soda can is located within a graspable range. Not only does this simplify the logical calculations required by the machine but it also increases the machine’s efficiency since the robotic hand is actually operating in a semi-autonomous manner. Third, for some tasks it is not necessary to construct a detailed internal model of the environment for the purpose of planning complex navigation and control behaviors. Rather, complex and creative navigation and control behaviors can naturally arise out of a small number of relatively simpler modular behaviors such as: grasping, wall following, and arm extending. Moreover, these simpler modular behaviors can be driven by affordances and do not require a detailed model of the world.<br/>And fourth, complex and creative behaviors can be created without planning through iterative interactions of a machine with its environment. I have a very smart dog which likes to catch balls but my dog is not very good at solving calculus problems. Even for a very smart dog, when we throw a ball to a dog who catches the ball in its mouth, the dog doesn’t accomplish this feat by solving a bunch of advanced calculus problems and then calculating the exact trajectory of the ball, moving to that spot, and then opening its jaws by the precise amount indicating by its mathematical calculations. Instead, the dog quickly estimates approximately the ball’s trajectory and then makes one or more additional adjustments in its physical location and orientation as the ball comes closer to the dog. The dog then takes another guess at where the ball will land and makes some additional minor physical adjustments to its location. This strategy is similar to that of the lunar lander vehicle robot which meets an obstacle and then iteratively repeats the cycle of backing up, changing orientation, and then moving forward again. Like the lunar lander, the dog actively interacts with its physical environment, to solve problems in an iterative manner.<br/>In conclusion, the concept of Embodied Cognition provides important insights into the analysis and design of artificially intelligent systems. The implementation of sophisticated artificially intelligent behaviors can be vastly simplified by not viewing the robot’s body as a mere instrument of the robot’s mind but rather by viewing the robot’s mind and the robot’s body as cooperating  as an integrated system for the purpose of generating smart behaviors with respect to a specific class of environments. And, even for non-robotic systems, such as machines that recognize speech and recognize patterns, Embodied Cognition can provide critical insights into the design of features for representing affordances in the machine’s external environment.  Embodied cognition argues that the design of artificially intelligent systems must incorporate a functional analysis of how the machine’s sensors process information. It also must incorporate an analysis of how the machine’s actuators alter its environment. And finally, it must be appreciated that such interactions often do not take place in a single step but are often iteratively repeated over time in a recurring cycle of perception and then action.<br/></div></body></html>